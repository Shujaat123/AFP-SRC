{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "AFP-SRC-Python",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Shujaat123/AFP-SRC/blob/master/AFP_SRC_Python.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-tcc6qiBvH3A",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2d1e5d47-3771-40c5-972b-ef09fc040a94"
      },
      "source": [
        "import sys, os, re, gc\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from random import sample\n",
        "\n",
        "## Models\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "from keras.models import Model\n",
        "from keras.layers import Input, Dense, BatchNormalization, Dropout\n",
        "from keras import metrics\n",
        "from keras import optimizers\n",
        "from keras.utils.np_utils import to_categorical\n",
        "\n",
        "import numpy.linalg as LA\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "## Perfmetrics\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import classification_report, accuracy_score, matthews_corrcoef, balanced_accuracy_score, precision_recall_fscore_support\n",
        "from sklearn.metrics import auc, average_precision_score, precision_recall_curve, roc_curve\n",
        "\n",
        "## utilities\n",
        "from matplotlib import pyplot as plt\n",
        "!pip install wget\n",
        "import wget"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: wget in /usr/local/lib/python3.7/dist-packages (3.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sgdn_gWhortw"
      },
      "source": [
        "file1_path = 'https://raw.githubusercontent.com/NLPrinceton/sparse_recovery/master/solvers.py'\n",
        "wget.download(file1_path, 'solvers.py')\n",
        "from solvers import *"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M679bns3u7p7"
      },
      "source": [
        "## Define CKSAAP feature-extraction function\n",
        "def minSequenceLength(fastas):\n",
        "\tminLen = 10000\n",
        "\tfor i in fastas:\n",
        "\t\tif minLen > len(i[1]):\n",
        "\t\t\tminLen = len(i[1])\n",
        "\treturn minLen\n",
        "\n",
        "def CKSAAP(fastas, gap=5, **kw):\n",
        "\tif gap < 0:\n",
        "\t\tprint('Error: the gap should be equal or greater than zero' + '\\n\\n')\n",
        "\t\treturn 0\n",
        "\n",
        "\tif minSequenceLength(fastas) < gap+2:\n",
        "\t\tprint('Error: all the sequence length should be larger than the (gap value) + 2 = ' + str(gap+2) + '\\n\\n')\n",
        "\t\treturn 0\n",
        "\n",
        "\tAA = 'ACDEFGHIKLMNPQRSTVWY'\n",
        "\tencodings = []\n",
        "\taaPairs = []\n",
        "\tfor aa1 in AA:\n",
        "\t\tfor aa2 in AA:\n",
        "\t\t\taaPairs.append(aa1 + aa2)\n",
        "\theader = ['#']\n",
        "\tfor g in range(gap+1):\n",
        "\t\tfor aa in aaPairs:\n",
        "\t\t\theader.append(aa + '.gap' + str(g))\n",
        "\tencodings.append(header)\n",
        "\tfor i in fastas:\n",
        "\t\tname, sequence = i[0], i[1]\n",
        "\t\tcode = [name]\n",
        "\t\tfor g in range(gap+1):\n",
        "\t\t\tmyDict = {}\n",
        "\t\t\tfor pair in aaPairs:\n",
        "\t\t\t\tmyDict[pair] = 0\n",
        "\t\t\tsum = 0\n",
        "\t\t\tfor index1 in range(len(sequence)):\n",
        "\t\t\t\tindex2 = index1 + g + 1\n",
        "\t\t\t\tif index1 < len(sequence) and index2 < len(sequence) and sequence[index1] in AA and sequence[index2] in AA:\n",
        "\t\t\t\t\tmyDict[sequence[index1] + sequence[index2]] = myDict[sequence[index1] + sequence[index2]] + 1\n",
        "\t\t\t\t\tsum = sum + 1\n",
        "\t\t\tfor pair in aaPairs:\n",
        "\t\t\t\tcode.append(myDict[pair] / sum)\n",
        "\t\tencodings.append(code)\n",
        "\treturn encodings"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "et6DhMTbqI3F"
      },
      "source": [
        "def delta_rule(A,delta_y,x,b):\n",
        "  # num_samples_per_class = int(x.shape[0]/2)\n",
        "  delta1 = 0*x\n",
        "  delta2 = 0*x\n",
        "  # delta1[0:num_samples_per_class] = x[0:num_samples_per_class]\n",
        "  # delta2[num_samples_per_class:] = x[num_samples_per_class:]\n",
        "\n",
        "  delta1[delta_y==1]=x[delta_y==1]\n",
        "  delta2[delta_y==0]=x[delta_y==0]\n",
        "\n",
        "  y1 = np.matmul(A,delta1)\n",
        "  y2 = np.matmul(A,delta2)\n",
        "  # print(delta1.shape, delta2.shape, y1.shape, y2.shape)\n",
        "  r1 = np.linalg.norm(y1-b)\n",
        "  r2 = np.linalg.norm(y2-b)\n",
        "\n",
        "  if(r1<r2):\n",
        "    label = 1\n",
        "  else:\n",
        "    label = 0\n",
        "\n",
        "  return label\n"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iz3Q97vju6Ho"
      },
      "source": [
        "def yoden_index(y, y_pred):\n",
        "  epsilon = 1e-30\n",
        "  tn, fp, fn, tp = confusion_matrix(y, y_pred, labels=[0,1]).ravel()\n",
        "  j = (tp/(tp + fn + epsilon)) + (tn/(tn+fp + epsilon)) - 1\n",
        "  return j\n",
        "\n",
        "def pmeasure(y, y_pred):\n",
        "    epsilon = 1e-30\n",
        "    tn, fp, fn, tp = confusion_matrix(y, y_pred, labels=[0,1]).ravel()\n",
        "    sensitivity = tp / (tp + fn + epsilon)\n",
        "    specificity = tn / (tn + fp + epsilon)\n",
        "    f1score = (2 * tp) / (2 * tp + fp + fn + epsilon)\n",
        "    return ({'Sensitivity': sensitivity, 'Specificity': specificity, 'F1-Score': f1score})"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XDk5IAHJs3f4"
      },
      "source": [
        "def Calculate_Stats(y_actual,y_pred):\n",
        "  acc = accuracy_score(y_actual, y_pred)\n",
        "  sen = pmeasure(y_actual, y_pred)['Sensitivity']\n",
        "  spe = pmeasure(y_actual, y_pred)['Specificity']\n",
        "  f1 = pmeasure(y_actual, y_pred)['F1-Score']\n",
        "  mcc = matthews_corrcoef(y_actual, y_pred)\n",
        "  bacc = balanced_accuracy_score(y_actual, y_pred)\n",
        "  yi = yoden_index(y_actual, y_pred)\n",
        "  #auc = roc_auc_score(y_actual, y_pred)\n",
        "  \n",
        "  #pre, rec, _ = precision_recall_curve(y_actual, y_score, pos_label=1)\n",
        "  #fpr, tpr, _ = roc_curve(y_actual, y_score, pos_label=1)\n",
        "  #auroc = auc(fpr, tpr)\n",
        "  #aupr = auc(rec, pre)\n",
        "\n",
        "  return acc, sen, spe, f1, mcc, bacc, yi"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2yZMgda6FGMm"
      },
      "source": [
        "train_set = pd.read_csv(\"https://raw.githubusercontent.com/Shujaat123/AFP-SRC/master/data/train1.csv\")\n",
        "test_set = pd.read_csv(\"https://raw.githubusercontent.com/Shujaat123/AFP-SRC/master/data/test1.csv\")"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ua12za40GXE6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e8f659e0-f74d-47c6-a830-78b01bb9d8b9"
      },
      "source": [
        "X_train = train_set.iloc[:, 1:].to_numpy()\n",
        "y_train = np.asarray(train_set.CLASS)\n",
        "y_train[y_train=='AFP']=1\n",
        "y_train[y_train=='NON_AFP']=0\n",
        "# y_train = to_categorical(y_train)\n",
        "\n",
        "X_test = test_set.iloc[:, 1:].to_numpy()\n",
        "y_test = np.asarray(test_set.CLASS)\n",
        "y_test[y_test=='AFP']=1\n",
        "y_test[y_test=='NON_AFP']=0\n",
        "# y_test = to_categorical(y_test)\n",
        "\n",
        "# print(X_train.shape,X_test.shape)\n",
        "# print(y_train.shape,y_test.shape)\n",
        "\n",
        "X = np.concatenate((X_train,X_test),axis = 0)\n",
        "y = np.concatenate((y_train,y_test),axis = 0)\n",
        "\n",
        "print(X.shape, y.shape)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(9972, 840) (9972,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "je6SCERn2s0V"
      },
      "source": [
        "def custom_train_test_split(X,y,train_sample):\n",
        "  from random import sample\n",
        "  n_pos = sum(y==1)\n",
        "  n_neg = sum(y==0)\n",
        "  print(n_pos,n_neg)\n",
        "\n",
        "  pos_list = range(0,n_pos)\n",
        "  neg_list = range(0,n_neg)\n",
        "\n",
        "  train_pos_list = sample(pos_list,train_sample)\n",
        "  train_neg_list = sample(neg_list,train_sample)\n",
        "\n",
        "  test_pos_list = list(set(list(pos_list)) - set(train_pos_list))\n",
        "  test_neg_list = list(set(list(neg_list)) - set(train_neg_list))\n",
        "\n",
        "  pos_sample = X[y==1]\n",
        "  pos_label = y[y==1]\n",
        "\n",
        "  neg_sample = X[y==0]\n",
        "  neg_label = y[y==0]\n",
        "\n",
        "  X_train = np.concatenate((pos_sample[train_pos_list],neg_sample[train_neg_list]), axis=0)\n",
        "  y_train = np.concatenate((pos_label[train_pos_list],neg_label[train_neg_list]), axis=0)\n",
        "\n",
        "  X_test = np.concatenate((pos_sample[test_pos_list],neg_sample[test_neg_list]), axis=0)\n",
        "  y_test = np.concatenate((pos_label[test_pos_list],neg_label[test_neg_list]), axis=0)\n",
        "\n",
        "  print(X_train.shape, y_train.shape)\n",
        "  print(X_test.shape, y_test.shape)\n",
        "\n",
        "  return X_train, X_test, y_train, y_test\n"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jiJmhQCRhUps",
        "outputId": "5d912953-2572-4825-c37c-cca52f92ab55"
      },
      "source": [
        "# from sklearn.model_selection import train_test_split\n",
        "# X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=0.8, random_state=0)\n",
        "X_train, X_test, y_train, y_test = custom_train_test_split(X,y,300)\n",
        "\n",
        "from sklearn.decomposition import KernelPCA\n",
        "# transformer = KernelPCA(n_components=100, kernel='linear')\n",
        "transformer = KernelPCA(n_components=100, kernel='poly') # 'linear', 'poly', 'rbf', ‘sigmoid’, ‘cosine’\n",
        "transformer.fit_transform(X_train)\n",
        "X_train = transformer.transform(X_train)\n",
        "X_test = transformer.transform(X_test)\n",
        "\n",
        "X_train = np.transpose(X_train)\n",
        "y_train = np.transpose(y_train).astype(int)\n",
        "X_test = np.transpose(X_test)\n",
        "y_test = np.transpose(y_test).astype(int)\n",
        "\n",
        "print(X_train.shape,X_test.shape)\n",
        "print(y_train.shape,y_test.shape)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "481 9491\n",
            "(600, 840) (600,)\n",
            "(9372, 840) (9372,)\n",
            "(100, 600) (100, 9372)\n",
            "(600,) (9372,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2OjHUiNjjE70"
      },
      "source": [
        "def Test_SRC(A,delta_y,DATA,LABEL,verbose):\n",
        "  # A = X_train\n",
        "  # DATA = X_test\n",
        "  # LABEL = y_test\n",
        "  LABEL_PRED = []\n",
        "  count = 0\n",
        "  for ind in range(0,DATA.shape[1]):\n",
        "    b = DATA[:,ind]\n",
        "    x = NonnegativeBP(A, b, x0=None, tol=1E-4, niter=100, biter=32)\n",
        "    label_out = delta_rule(A,delta_y,x,b)\n",
        "    if (verbose):\n",
        "      check = label_out==LABEL[ind]\n",
        "      if (check):\n",
        "        count = count + 1\n",
        "      accuracy = 100*count/(ind+1)\n",
        "      print(ind+1, count, accuracy, LABEL[ind], label_out, check)\n",
        "    LABEL_PRED.append(label_out)\n",
        "\n",
        "  return np.array(LABEL_PRED)\n"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kzvVjTat2oy9",
        "outputId": "d63ce099-e5aa-46a9-b36f-c0d30a867596"
      },
      "source": [
        "y_train_pred = Test_SRC(X_train,y_train,X_train,y_train,0)\n",
        "# y_test_pred = Test_SRC(X_train,y_train,X_test,y_test,1)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/content/solvers.py:52: LinAlgWarning: Ill-conditioned matrix (rcond=8.80397e-17): result may not be accurate.\n",
            "  dv = solve(A.dot(AT*(x/lam)[:,np.newaxis]), rp-A.dot((rc+x*rd)/lam), assume_a='pos')\n",
            "/content/solvers.py:52: LinAlgWarning: Ill-conditioned matrix (rcond=5.86994e-17): result may not be accurate.\n",
            "  dv = solve(A.dot(AT*(x/lam)[:,np.newaxis]), rp-A.dot((rc+x*rd)/lam), assume_a='pos')\n",
            "/content/solvers.py:52: LinAlgWarning: Ill-conditioned matrix (rcond=2.67207e-17): result may not be accurate.\n",
            "  dv = solve(A.dot(AT*(x/lam)[:,np.newaxis]), rp-A.dot((rc+x*rd)/lam), assume_a='pos')\n",
            "/content/solvers.py:52: LinAlgWarning: Ill-conditioned matrix (rcond=2.55215e-17): result may not be accurate.\n",
            "  dv = solve(A.dot(AT*(x/lam)[:,np.newaxis]), rp-A.dot((rc+x*rd)/lam), assume_a='pos')\n",
            "/content/solvers.py:52: LinAlgWarning: Ill-conditioned matrix (rcond=3.48903e-17): result may not be accurate.\n",
            "  dv = solve(A.dot(AT*(x/lam)[:,np.newaxis]), rp-A.dot((rc+x*rd)/lam), assume_a='pos')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xeh-L3Jp7icZ"
      },
      "source": [
        "tr_acc, tr_sen, tr_spe, tr_f1, tr_mcc, tr_bacc, tr_yi = Calculate_Stats(y_train, y_train_pred)\n",
        "# t_acc, t_sen, t_spe, t_f1, t_mcc, t_bacc, t_yi = Calculate_Stats(y_test,y_test_pred)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1q7xddSyaSH6",
        "outputId": "7aecbda6-04c5-4175-cfad-0fa84dfadb97"
      },
      "source": [
        "print(tr_acc, tr_sen, tr_spe, tr_f1, tr_mcc, tr_bacc, tr_yi)\n",
        "# print(t_acc, t_sen, t_spe, t_f1, t_mcc, t_bacc, t_yi)\n"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.0 1.0 1.0 1.0 1.0 1.0 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q3JRklKvsgnH"
      },
      "source": [
        "# Stats=[]\n",
        "\n",
        "# for i in range(3):\n",
        "#   y_train_pred = train_list[i]\n",
        "#   y_test_pred = test_list[i]\n",
        "  \n",
        "#   ## Training Measures\n",
        "#   tr_acc, tr_sen, tr_spe, tr_f1, tr_mcc, tr_bacc, tr_yi = Calculate_Stats(y_train, y_train_pred);\n",
        "  \n",
        "#   ## Validation Measures\n",
        "#   #v_acc, v_sen, v_spe, v_f1, v_mcc, v_bacc, v_yi = Calculate_Stats(to_categorical(y_val),y_val_pred);\n",
        "  \n",
        "#   ## Test Measures\n",
        "#   t_acc, t_sen, t_spe, t_f1, t_mcc, t_bacc, t_yi = Calculate_Stats(y_test,y_test_pred);\n",
        "\n",
        "#   Stats.append([tr_acc, tr_sen, tr_spe, tr_f1, tr_mcc, tr_bacc, tr_yi,\n",
        "#                 #              v_acc, v_sen, v_spe, v_f1, v_mcc, v_bacc, v_yi,\n",
        "#                 t_acc, t_sen, t_spe, t_f1, t_mcc, t_bacc, t_yi])\n",
        "\n",
        "# Statistics = np.asarray(Stats)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GaCNG--RtbIx"
      },
      "source": [
        "# def Show_Statistics(msg,mean_Stats, sd_Stats, sigfig):\n",
        "#   print(msg.upper())\n",
        "#   print(70*'-')\n",
        "#   print('Accuracy:{} + {}'          .format(round(mean_Stats[0],sigfig), round(sd_Stats[0],sigfig)))\n",
        "#   print('Sensitivity:{} + {} '      .format(round(mean_Stats[1],sigfig), round(sd_Stats[1],sigfig)))\n",
        "#   print('Specificity:{} + {}'       .format(round(mean_Stats[2],sigfig), round(sd_Stats[2],sigfig)))\n",
        "#   print('F1-Score:{} + {}'          .format(round(mean_Stats[3],sigfig), round(sd_Stats[3],sigfig)))\n",
        "#   print('MCC:{} + {}'               .format(round(mean_Stats[4],sigfig), round(sd_Stats[4],sigfig)))\n",
        "#   print('Balance Accuracy:{} + {}'  .format(round(mean_Stats[5],sigfig), round(sd_Stats[5],sigfig)))\n",
        "#   print('Youden-Index:{} + {}'      .format(round(mean_Stats[6],sigfig), round(sd_Stats[6],sigfig)))\n",
        "#   print(70*'-')"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1uvCv738thYf"
      },
      "source": [
        "# Show_Statistics('Norm Training Results (MEAN)',Statistics[0][0:7],Statistics.std(axis=0)[0:7], 3)\n",
        "# Show_Statistics('Norm Test Results (MEAN)',Statistics[0][7:14],Statistics.std(axis=0)[7:14], 3)\n",
        "# Show_Statistics('Dict Training Results (MEAN)',Statistics[1][0:7],Statistics.std(axis=0)[0:7], 3)\n",
        "# Show_Statistics('Dict Test Results (MEAN)',Statistics[1][7:14],Statistics.std(axis=0)[7:14], 3)\n",
        "# Show_Statistics('Rec Training Results (MEAN)',Statistics[2][0:7],Statistics.std(axis=0)[0:7], 3)\n",
        "# Show_Statistics('Rec Test Results (MEAN)',Statistics[2][7:14],Statistics.std(axis=0)[7:14], 3)\n",
        "# #Show_Statistics('Test Results (MEAN)',Statistics.mean(axis=0)[14:21],Statistics.std(axis=0)[14:21], 3)"
      ],
      "execution_count": 17,
      "outputs": []
    }
  ]
}